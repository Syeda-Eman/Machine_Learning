{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa336e9",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; border-radius:15px; padding:15px; color:white; margin:0; font-family: 'Orbitron', sans-serif; background: #2E0249; background: #11001C; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3); overflow:hidden; margin-bottom: 1em;\">\n",
    "    <div style=\"font-size:150%; color:#FEE100\"><b>Hajj Pilgrimage Data Analysis and Predictor Notebook</b></div>\n",
    "    <div>This notebook was created with the help of <a href=\"https://devra.ai/ref/kaggle\" style=\"color:#6666FF\">Devra AI</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ecae51",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Data Loading and Inspection](#Data-Loading-and-Inspection)\n",
    "- [Data Cleaning and Preprocessing](#Data-Cleaning-and-Preprocessing)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Prediction Model](#Prediction-Model)\n",
    "- [Conclusions and Future Work](#Conclusions-and-Future-Work)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b56a13",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we dive into the synthetic Hajj pilgrimage dataset. The Hajj is one of the largest annual gatherings in the world, and this dataset provides insight into various characteristics of the pilgrims such as their country, gender, age group, accommodation type, transport type, estimated spending in Saudi Riyal, and group sizes. The aim here is to explore the data, perform necessary cleaning and preprocessing, visualize distributions and relationships, and build a regression predictor for estimating spending. If you find this analysis useful, upvote it.\n",
    "\n",
    "Let's get started with our journey into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Ensure the proper backend is used\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')  # For cases when plt module is imported\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# For predictive modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Ensure inline plotting when appropriate\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482209f",
   "metadata": {},
   "source": [
    "## Data Loading and Inspection\n",
    "\n",
    "In this section we load the synthetic Hajj dataset and inspect the first few rows as well as the data types. Note that the dataset is encoded in ASCII and uses comma as the delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('synthetic_hajj_dataset.csv', delimiter=',', encoding='ascii')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print('First five rows of the dataset:')\n",
    "print(df.head())\n",
    "\n",
    "# Display the dataframe info to inspect column types\n",
    "print('\\nDataframe Info:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425cba02",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "We now perform data cleaning and preprocessing. The dataset appears to have categorical columns with string values and few numeric columns. Although there is no explicit date column in this dataset, if there were, we would infer the date type.\n",
    "\n",
    "We also check for missing values and duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print('\\nNumber of duplicate rows:', df.duplicated().sum())\n",
    "\n",
    "# Drop duplicates if necessary\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert columns with categorical information to category dtype if appropriate\n",
    "categorical_columns = ['Country', 'Gender', 'Age_Group', 'Accommodation_Type', 'Transport_Type', 'Stay_Duration']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Check data types after conversion\n",
    "print('\\nData types after conversion:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90318bf8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Here we explore the distribution and relationships of the various columns in the dataset using a variety of visualization techniques. We use histograms and box plots for numeric columns, count plots (pie charts) for categorical columns, pair plots for numeric relationships, and more. \n",
    "\n",
    "Note that when constructing correlation heatmaps it is advisable to filter the dataframe to only numeric columns. In this case, we only have three numeric columns (Pilgrim_ID, Estimated_Spending_SAR, Group_Size), which is less than four; therefore, we skip the correlation heatmap as it might not be very insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Plot histograms for numeric columns\n",
    "for col in numeric_df.columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(numeric_df[col], kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate a pairplot for numeric features (even though we have only three columns)\n",
    "sns.pairplot(numeric_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot count plots for categorical data\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(data=df, x=col, order=df[col].value_counts().index)\n",
    "    plt.title(f'Count Plot for {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Box plot for numeric columns vs. categorical group: Estimated_Spending_SAR by Gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df, x='Gender', y='Estimated_Spending_SAR')\n",
    "plt.title('Estimated Spending by Gender')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for numeric columns vs. categorical group: Group_Size by Accommodation_Type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=df, x='Accommodation_Type', y='Group_Size')\n",
    "plt.title('Group Size by Accommodation Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511943f",
   "metadata": {},
   "source": [
    "## Prediction Model\n",
    "\n",
    "It might be useful to predict the Estimated Spending of a pilgrim based on other features. Here we build a regression predictor to estimate the 'Estimated_Spending_SAR'. We use a RandomForestRegressor after encoding the categorical features. \n",
    "\n",
    "Note: When encoding categorical variables, the approach used here is label encoding for simplicity; however, in a production scenario, one might consider more robust methods such as one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe to work on for prediction\n",
    "df_model = df.copy()\n",
    "\n",
    "# We need to encode categorical variables. For simplicity, we will use pandas' factorize\n",
    "for col in categorical_columns:\n",
    "    df_model[col] = pd.factorize(df_model[col])[0]\n",
    "\n",
    "# Define the target and features\n",
    "target = 'Estimated_Spending_SAR'\n",
    "features = [col for col in df_model.columns if col != target and col != 'Pilgrim_ID']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_model[features], df_model[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model using R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R^2 Score of the Regression Model: {r2:.3f}\")\n",
    "\n",
    "# Feature importance visualization using permutation importance style\n",
    "importances = rf_regressor.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Permutation Importance of Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaff376",
   "metadata": {},
   "source": [
    "## Conclusions and Future Work\n",
    "\n",
    "This notebook provided an exploratory analysis of the synthetic Hajj dataset, followed by building a regression predictor that estimates the spending of pilgrims. The approach covered data inspection, preprocessing, a spectrum of visualizations, and a machine learning model. \n",
    "\n",
    "Merits of this approach include:\n",
    "\n",
    "- A thorough examination of both categorical and numeric features using varied plot types.\n",
    "- Addressing potential common errors (like date parsing and missing values) even if they were not present in this dataset.\n",
    "- A simple yet effective regression model with evaluation via the R^2 score.\n",
    "\n",
    "For future analysis, one might: \n",
    "\n",
    "- Explore advanced feature engineering (e.g., interaction terms between categorical features).\n",
    "- Compare different regression models or even try a classification approach based on spending brackets.\n",
    "- Incorporate external data sources to enhance the richness of the analysis.\n",
    "\n",
    "If you found this notebook useful, please give it an upvote."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  },
  "toc_autonumber": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
